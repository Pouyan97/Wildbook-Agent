{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from misc import loadProperties, loadWEKA\n",
    "\n",
    "props = loadProperties('submitActionClass.properties')\n",
    "(data, attr) = loadWEKA('youTubeLocationIDWeka.csv', limit=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjusting spacy's pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import Span\n",
    "from spacy.matcher import PhraseMatcher\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "locations = [x for x in props] # Array of known locations from .properties\n",
    "location_patterns = list(nlp.pipe(locations))\n",
    "\n",
    "matcher = PhraseMatcher(nlp.vocab, attr='LOWER')\n",
    "matcher.add(\"LOCATION\", None, *location_patterns)\n",
    "\n",
    "# Define the custom component\n",
    "def location_component(doc):\n",
    "    # Apply the matcher to the doc\n",
    "    matches = matcher(doc)\n",
    "    # Create a Span for each match and assign the label 'LOCATION'\n",
    "    # Overwrite the doc.ents with the matched spans\n",
    "    doc.ents = [Span(doc, start, end, label=\"LOCATION\") for match_id, start, end in matches]\n",
    "    return doc\n",
    "\n",
    "# Add the component to the pipeline after the 'ner' component\n",
    "nlp.add_pipe(location_component, before='ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses spacy to look up for location in a strings. Returns Array of matches\n",
    "def nlpLocation(string):\n",
    "    spacy_mathc = []\n",
    "    for ent in nlp(string).ents:\n",
    "        if ent.label_ == \"GPE\" or ent.label_ == \"LOCATION\":\n",
    "            spacy_mathc.append(ent.text.lower())\n",
    "    return spacy_mathc\n",
    "\n",
    "def matchLocationV3(item_original):\n",
    "    item = item_original.copy()\n",
    "    locations = []\n",
    "\n",
    "    locations += nlpLocation(item[2].replace(\"'\",\"\")) # Title\n",
    "    locations += nlpLocation(item[3].replace(\"'\",\"\")) # Tags\n",
    "    locations += nlpLocation(item[4].replace(\"'\",\"\")) # Descr\n",
    "      \n",
    "    item.append(locations)\n",
    "    return item\n",
    "\n",
    "# matchLocationV3(data2[405])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeDuplicateLocation(item_original):\n",
    "    item = item_original.copy()\n",
    "    item[7] = list(set(item[7]))\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printItem(item_original):\n",
    "    print(item_original)\n",
    "    print()\n",
    "    return item_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onlyItemsWithPayload(item_original):\n",
    "    if item_original[2] or item_original[3] or item_original[4]:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onlyItemsWithMatchedLocation(item_original):\n",
    "    if len(item_original[7]) > 0:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countStats(acc, item):\n",
    "    # Counting stats\n",
    "    acc[\"total\"] += 1\n",
    "    if item[2] or item[3] or item[4]:\n",
    "        acc[\"hasDataToAnalyze\"] += 1\n",
    "    if len(item[7]) > 0:\n",
    "        acc[\"identified\"] += 1\n",
    "    return acc\n",
    "def printStats(stats):\n",
    "    print(stats[\"total\"], \"items were processed in total.\")\n",
    "    print(stats[\"hasDataToAnalyze\"], \"of them had title,description or tags to analyze.\")\n",
    "    print(stats[\"identified\"], \"out of\", stats[\"hasDataToAnalyze\"], \"were matched with potential location\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "matchLocationV3: 100%|██████████| 1800/1800 [00:05<00:00, 322.50it/s]\n",
      "removeDuplicateLocation: 100%|██████████| 1800/1800 [00:00<00:00, 633527.50it/s]\n",
      "countStats: 100%|██████████| 1800/1800 [00:00<00:00, 1061849.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800 items were processed in total.\n",
      "394 of them had title,description or tags to analyze.\n",
      "19 out of 394 were matched with potential location\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "onlyItemsWithMatchedLocation: 100%|██████████| 1800/1800 [00:00<00:00, 1351306.10it/s]\n"
     ]
    }
   ],
   "source": [
    "from customPipeline import Pipe\n",
    "data = data[:1800]\n",
    "\n",
    "pl = Pipe()\n",
    "# pl.addDataPipe(onlyItemsWithPayload)\n",
    "pl.addItemPipe(matchLocationV3)\n",
    "pl.addItemPipe(removeDuplicateLocation)\n",
    "pl.addStatPipe(countStats, printStats, {\"total\":0, \"hasDataToAnalyze\":0, \"identified\":0})\n",
    "pl.addDataPipe(onlyItemsWithMatchedLocation)\n",
    "# pl.addPipe(printItem)\n",
    "result = pl(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
