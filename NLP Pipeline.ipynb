{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from misc import loadProperties, loadWEKA\n",
    "\n",
    "props = loadProperties('submitActionClass.properties')\n",
    "(data, attr) = loadWEKA('youTubeLocationIDWeka.csv', limit=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjusting spacy's pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import Span\n",
    "from spacy.matcher import PhraseMatcher\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "locations = [x for x in props] # Array of known locations from .properties\n",
    "location_patterns = list(nlp.pipe(locations))\n",
    "\n",
    "matcher = PhraseMatcher(nlp.vocab, attr='LOWER')\n",
    "matcher.add(\"LOCATION\", None, *location_patterns)\n",
    "\n",
    "# Define the custom component\n",
    "def location_component(doc):\n",
    "    # Apply the matcher to the doc\n",
    "    matches = matcher(doc)\n",
    "    # Create a Span for each match and assign the label 'LOCATION'\n",
    "    # Overwrite the doc.ents with the matched spans\n",
    "    doc.ents = [Span(doc, start, end, label=\"LOCATION\") for match_id, start, end in matches]\n",
    "    return doc\n",
    "\n",
    "# Add the component to the pipeline after the 'ner' component\n",
    "nlp.add_pipe(location_component, before='ner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining functions for pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns [videoId, [Title,Descr,Tags]]\n",
    "def preprocessWekaData(item_original):\n",
    "    item = [ item_original[0],[] ]\n",
    "    \n",
    "    # Going through title,descr,tags\n",
    "    for i in range(2,5):\n",
    "        if item_original[i]:\n",
    "            item[1].append(item_original[i])\n",
    "            \n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onlyItemsWithPayload(item_original):\n",
    "    if len(item_original[1]) > 0:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses spacy to look up for location in a strings. Returns Array of matches\n",
    "def nlpLocation(string):\n",
    "    spacy_mathc = []\n",
    "    for ent in nlp(string).ents:\n",
    "        if ent.label_ == \"GPE\" or ent.label_ == \"LOCATION\":\n",
    "            spacy_mathc.append(ent.text.lower())\n",
    "    return spacy_mathc\n",
    "\n",
    "def matchLocationV3(item_original):\n",
    "    item = item_original.copy()\n",
    "    locations = []\n",
    "    \n",
    "    # Going through potential data to analyze\n",
    "    for text in item[1]:\n",
    "        locations += nlpLocation(text.replace(\"'\",\"\")) # Title\n",
    "      \n",
    "    item.append(locations)\n",
    "    return item\n",
    "\n",
    "# matchLocationV3(data2[405])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeDuplicateLocation(item_original):\n",
    "    item = item_original.copy()\n",
    "    item[2] = list(set(item[2]))\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onlyItemsWithMatchedLocation(item_original):\n",
    "    if len(item_original[2]) > 0:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printItem(item_original):\n",
    "    print(item_original)\n",
    "    print()\n",
    "    return item_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countStats(stats, item):\n",
    "    stats[\"total\"] += 1\n",
    "    if len(item[1]) > 0:\n",
    "        stats[\"hasDataToAnalyze\"] += 1\n",
    "    if len(item[2]) > 0:\n",
    "        stats[\"identified\"] += 1\n",
    "    return stats\n",
    "def printStats(stats):\n",
    "    print(stats[\"total\"], \"items were processed in total.\")\n",
    "    print(stats[\"hasDataToAnalyze\"], \"of them had title,description or tags to analyze.\")\n",
    "    print(stats[\"identified\"], \"out of\", stats[\"hasDataToAnalyze\"], \"were matched with potential location\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing and running the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "preprocessWekaData: 100%|██████████| 1800/1800 [00:00<00:00, 570351.83it/s]\n",
      "onlyItemsWithPayload: 100%|██████████| 1800/1800 [00:00<00:00, 1052522.96it/s]\n",
      "matchLocationV3: 100%|██████████| 394/394 [00:03<00:00, 123.75it/s]\n",
      "removeDuplicateLocation: 100%|██████████| 394/394 [00:00<00:00, 507853.65it/s]\n",
      "countStats: 100%|██████████| 394/394 [00:00<00:00, 508478.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394 items were processed in total.\n",
      "394 of them had title,description or tags to analyze.\n",
      "19 out of 394 were matched with potential location\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "onlyItemsWithMatchedLocation: 100%|██████████| 394/394 [00:00<00:00, 425477.80it/s]\n"
     ]
    }
   ],
   "source": [
    "from customPipeline import Pipe\n",
    "data = data[:1800]\n",
    "\n",
    "pl = Pipe()\n",
    "pl.addItemPipe(preprocessWekaData)\n",
    "pl.addDataPipe(onlyItemsWithPayload)\n",
    "pl.addItemPipe(matchLocationV3)\n",
    "pl.addItemPipe(removeDuplicateLocation)\n",
    "pl.addStatPipe(countStats, printStats, {\"total\":0, \"hasDataToAnalyze\":0, \"identified\":0})\n",
    "pl.addDataPipe(onlyItemsWithMatchedLocation)\n",
    "# pl.addItemPipe(printItem)\n",
    "result = pl(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to work with GeoNames API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def geoNamesSearch(item_original):\n",
    "    item = item_original.copy()\n",
    "    results = {}\n",
    "    \n",
    "    # Going through each identified location\n",
    "    for loc in item[2]:\n",
    "        r = \"http://api.geonames.org/search?type=json&fuzzy=0.4&formatted=true&maxRows=3&username=kirillovmr&style=short&q=\"+loc\n",
    "        resp = requests.get(r).json()\n",
    "        \n",
    "        if len(resp['geonames']) > 0:\n",
    "            results[loc] = []\n",
    "            # Going through each result\n",
    "            for geoItem in resp['geonames']:\n",
    "                results[loc].append(geoItem)\n",
    "    \n",
    "    item.append(results)\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __areHierarchyLocationsCloseToEachOther(hierarchy):\n",
    "    allowedDifference = 10\n",
    "    deepestLocationsLat = []\n",
    "    deepestLocationsLng = []\n",
    "    averageLocation = [0,0]\n",
    "    difference = [0,0]\n",
    "    \n",
    "    for item in hierarchy:\n",
    "        lat = float(item[len(item)-1]['lat'])\n",
    "        lng = float(item[len(item)-1]['lng'])\n",
    "        deepestLocationsLat.append(lat)\n",
    "        deepestLocationsLng.append(lng)\n",
    "        averageLocation[0] += lat\n",
    "        averageLocation[1] += lng\n",
    "    \n",
    "    # Calculating average\n",
    "    numLocations = len(deepestLocationsLat)\n",
    "    averageLocation[0] /= numLocations\n",
    "    averageLocation[1] /= numLocations\n",
    "    \n",
    "    # Calculating difference\n",
    "    for i in range(numLocations):\n",
    "        difference[0] += (abs(deepestLocationsLat[i]) - abs(averageLocation[0])) ** 2\n",
    "        difference[1] += (abs(deepestLocationsLng[i]) - abs(averageLocation[1])) ** 2\n",
    "        \n",
    "    # Checking actual difference with allowed\n",
    "    for i in range(2):\n",
    "        if difference[i] > allowedDifference:\n",
    "            return False\n",
    "    \n",
    "    # Difference within allowed range\n",
    "    return True\n",
    "\n",
    "def remainMostSpecificLocations(item_original):\n",
    "    item = item_original.copy()\n",
    "    \n",
    "    # Going through each key\n",
    "    for identifiedLocationName in item[3]:\n",
    "        # Going through each location object\n",
    "        hierarchy = []\n",
    "        for locObj in item[3][identifiedLocationName]:\n",
    "            # Getting hierarchy for each location id\n",
    "            r = \"http://api.geonames.org/hierarchy?type=json&formatted=true&username=kirillovmr&style=short&geonameId=\"+str(locObj['geonameId'])\n",
    "            resp = requests.get(r).json()\n",
    "            hierarchy.append(resp['geonames'])\n",
    "        print(\"Hierarchy for\", identifiedLocationName, \"close?\", __areHierarchyLocationsCloseToEachOther(hierarchy))\n",
    "    \n",
    "    return item\n",
    "\n",
    "# res3 = remainMostSpecificLocations(result2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "geoNamesSearch: 100%|██████████| 1/1 [00:01<00:00,  1.97s/it]\n",
      "remainMostSpecificLocations:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hierarchy for barbadoswhich close? False\n",
      "Hierarchy for sw close? False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "remainMostSpecificLocations: 100%|██████████| 1/1 [00:02<00:00,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hierarchy for belize close? True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pl2 = Pipe()\n",
    "pl2.addItemPipe(geoNamesSearch)\n",
    "pl2.addItemPipe(remainMostSpecificLocations)\n",
    "result2 = pl2(result[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['19112010171749',\n",
       " ['Was on shore and saw a huge splashsaw a giant grey creature moving at surface like a powerful submarineit was fairly far outthen saw a huge flopping dorsal fin then a smaller second fin at first I thought 2 dolphins but it was an enormous fish swimming in the seathe largest I have ever seen in my lifeno one believed me but about 6 weeks laterthis weeka fisherman reported being terrified by a giant 40 sea monsterwith a huge open mouthcoming straight at his boat3 miles of the SW of Barbadoswhich is about 5 or 6 miles downwind from my beach His deion matched what I knew I sawhe said he tried clubbing itplease look into this quickly as it would be terrible for a creature like this to sufferthey are not known to be around Barbadosin recent times but I see Belize and Gulf of Mexico have a lot so there is no reason why one could not be over this side of the Caribbean'],\n",
       " ['barbadoswhich', 'sw', 'belize'],\n",
       " {'barbadoswhich': [{'lng': '-59.55165',\n",
       "    'geonameId': 3374084,\n",
       "    'countryCode': 'BB',\n",
       "    'name': 'Barbados',\n",
       "    'toponymName': 'Barbados',\n",
       "    'lat': '13.16453',\n",
       "    'fcl': 'A',\n",
       "    'fcode': 'PCLI'},\n",
       "   {'lng': '-70.93246',\n",
       "    'geonameId': 5082987,\n",
       "    'countryCode': 'US',\n",
       "    'name': 'Barbadoes Pond',\n",
       "    'toponymName': 'Barbadoes Pond',\n",
       "    'lat': '43.19029',\n",
       "    'fcl': 'H',\n",
       "    'fcode': 'LK'},\n",
       "   {'lng': '26.0139',\n",
       "    'geonameId': 630429,\n",
       "    'countryCode': 'BY',\n",
       "    'name': 'Baranovichi',\n",
       "    'toponymName': 'Baranovichi',\n",
       "    'lat': '53.1327',\n",
       "    'fcl': 'P',\n",
       "    'fcode': 'PPLA2'}],\n",
       "  'sw': [{'lng': '46.9093',\n",
       "    'geonameId': 113847,\n",
       "    'countryCode': 'IR',\n",
       "    'name': 'Sū',\n",
       "    'toponymName': 'Sū',\n",
       "    'lat': '35.1576',\n",
       "    'fcl': 'P',\n",
       "    'fcode': 'PPL'},\n",
       "   {'lng': '7.53195',\n",
       "    'geonameId': 11962896,\n",
       "    'countryCode': 'CH',\n",
       "    'name': 'Solothurn West',\n",
       "    'toponymName': 'Solothurn West',\n",
       "    'lat': '47.20671',\n",
       "    'fcl': 'S',\n",
       "    'fcode': 'RSTN'},\n",
       "   {'lng': '80.29935',\n",
       "    'geonameId': 1256911,\n",
       "    'countryCode': 'IN',\n",
       "    'name': 'Sehrāmaū',\n",
       "    'toponymName': 'Sehrāmaū',\n",
       "    'lat': '28.35804',\n",
       "    'fcl': 'S',\n",
       "    'fcode': 'RSTN'}],\n",
       "  'belize': [{'lng': '-88.75',\n",
       "    'geonameId': 3582678,\n",
       "    'countryCode': 'BZ',\n",
       "    'name': 'Belize',\n",
       "    'toponymName': 'Belize',\n",
       "    'lat': '17.25',\n",
       "    'fcl': 'A',\n",
       "    'fcode': 'PCLI'},\n",
       "   {'lng': '-88.19756',\n",
       "    'geonameId': 3582677,\n",
       "    'countryCode': 'BZ',\n",
       "    'name': 'Belize City',\n",
       "    'toponymName': 'Belize City',\n",
       "    'lat': '17.49952',\n",
       "    'fcl': 'P',\n",
       "    'fcode': 'PPLA'},\n",
       "   {'lng': '-88.41667',\n",
       "    'geonameId': 3582676,\n",
       "    'countryCode': 'BZ',\n",
       "    'name': 'Belize District',\n",
       "    'toponymName': 'Belize District',\n",
       "    'lat': '17.55',\n",
       "    'fcl': 'A',\n",
       "    'fcode': 'ADM1'}]}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
